{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 Pytorch 的矩阵计算的相关练习\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵的基本操作\n",
    "\n",
    "好的，以下是 PyTorch 矩阵计算基本操作的汇总表格：\n",
    "\n",
    "| 操作类型 | 具体操作 | 说明 | 示例 |\n",
    "| - | - | - | - |\n",
    "| **创建张量** | `torch.Tensor()` | 创建多维数组 | `torch.Tensor([1, 2, 3])` |\n",
    "| | `torch.zeros()` | 创建全零张量 | `torch.zeros((2, 3))` |\n",
    "| | `torch.ones()` | 创建全一张量 | `torch.ones((2, 3))` |\n",
    "| | `torch.randn()` | 创建服从标准正态分布的随机数张量 | `torch.randn((2, 3))` |\n",
    "| **基本运算** | `torch.add()` / `+` | 加法 | `torch.add(a, b)` / `a + b` |\n",
    "| | `torch.sub()` / `-` | 减法 | `torch.sub(a, b)` / `a - b` |\n",
    "| | `torch.mul()` / `*` | 元素级乘法 | `torch.mul(a, b)` / `a * b` |\n",
    "| | `torch.div()` / `/` | 除法 | `torch.div(a, b)` / `a / b` |\n",
    "| | `torch.matmul()` / `torch.mm()` / `@` | 矩阵乘法 | `torch.matmul(a, b)` / `a @ b` |\n",
    "| **矩阵操作** | `torch.t()` / `torch.transpose()` | 转置 | `torch.t(a)` / `torch.transpose(a, 0, 1)` |\n",
    "| | `torch.reshape()` / `torch.view()` | 重塑 | `torch.reshape(a, (2, 3))` / `a.view(2, 3)` |\n",
    "| | 索引和切片 | 访问和修改张量元素 | `a[0, 1]` / `a[:, 1:]` |\n",
    "| | `torch.cat()` / `torch.stack()` | 连接 | `torch.cat((a, b), dim=0)` / `torch.stack((a, b), dim=0)` |\n",
    "| **统计操作** | `torch.mean()` | 均值 | `torch.mean(a)` |\n",
    "| | `torch.sum()` | 总和 | `torch.sum(a)` |\n",
    "| | `torch.max()` | 最大值 | `torch.max(a)` |\n",
    "| | `torch.min()` | 最小值 | `torch.min(a)` |\n",
    "| **线性代数** | `torch.inverse()` | 逆矩阵 | `torch.inverse(a)` |\n",
    "| | `torch.det()` | 行列式 | `torch.det(a)` |\n",
    "| | `torch.eig()` | 特征值和特征向量 | `torch.eig(a)` |\n",
    "\n",
    "\n",
    "**补充说明：**\n",
    "\n",
    "* `a` 和 `b` 代表张量。\n",
    "* `dim` 代表维度。\n",
    "* 请根据你的具体需求选择合适的操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **标量（Scalar）和张量（Tensor）**\n",
    "> \n",
    "> 张量是一个多维数组，可以看作是标量、向量和矩阵的推广。张量的维度（或阶）决定了它的复杂性：\n",
    "> \n",
    "> - 标量（0阶张量）是一个单一的数值，例如：$ 5,\\pi $。\n",
    "> - 向量（1阶张量）是一维数组，例如：$ [1, 2, 3] $。\n",
    "> - 矩阵（2阶张量）是二维数组，例如：$\\bigl( \\begin{smallmatrix} 1 & 2 \\\\ 3 & 4 \\end{smallmatrix} \\bigr)$\n",
    "> \n",
    "> 高阶张量是三维或更高维的数组，例如三维张量可以表示为一个立方体的数据。\n",
    "> \n",
    "> 张量在机器学习和深度学习中非常重要，因为它们可以表示复杂的数据结构，如图像、视频和时间序列数据。\n",
    "> \n",
    "> 标量是一个单一的数值，没有方向和维度。它是最简单的张量（0阶张量）。标量可以是整数、浮点数或复数等。例如：$ 5,\\pi,3.14 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **点积与乘法的区别**\n",
    ">\n",
    "> 点积（又称内积）和乘法是线性代数和代数中的两个不同概念。点积是两个向量之间的操作，结果是一个标量。点积的公式：$ \\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i $\n",
    ">\n",
    "> 其中，$ \\mathbf{a} $ 和 $ \\mathbf{b} $ 是两个向量，$a_i$和$b_i$ 是向量的对应分量。\n",
    ">\n",
    "> 点积的几何意义是两个向量在空间中的投影长度乘积。它可以用于计算两个向量之间的夹角。\n",
    ">\n",
    "> 乘法通常指的是标量乘法或矩阵乘法。标量乘法是两个数之间的操作，结果也是一个数。例如：$ a \\times b = c $\n",
    ">\n",
    "> 其中，$ a $和$ b $是两个数，$ c $是它们的乘积。\n",
    ">\n",
    "> 矩阵乘法是两个矩阵之间的操作，结果是一个新的矩阵。矩阵乘法的规则：$ (AB)_{ij} = \\sum_{k} A_{ik} B_{kj} $\n",
    ">\n",
    "> 其中，$ A $和$ B $是两个矩阵，$ A_{ik} $和$ B_{kj} $是矩阵的元素。\n",
    ">\n",
    "> **在 PyTorch 中，两个向量的点积不可以用 `*` 表示**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵的高级操作\n",
    "\n",
    "| 操作类别 | 具体操作 | 说明 |\n",
    "| - | - | - |\n",
    "| **线性代数操作** | `torch.linalg.cholesky()` | Cholesky 分解 |\n",
    "| | `torch.linalg.qr()` | QR 分解 |\n",
    "| | `torch.linalg.svd()` | 奇异值分解（SVD） |\n",
    "| | `torch.linalg.eig()` | 计算复数域上的特征值和特征向量 |\n",
    "| | `torch.linalg.eigh()` | 计算实对称或复 Hermitian 矩阵的特征值和特征向量 |\n",
    "| | `torch.linalg.inv()` | 计算矩阵的逆 |\n",
    "| | `torch.linalg.det()` | 计算矩阵的行列式 |\n",
    "| | `torch.linalg.solve()` | 求解线性方程组 |\n",
    "| **张量操作** | 高级索引 (gather, scatter) | 使用整数或布尔张量索引，进行数据收集或分散 |\n",
    "| | `torch.squeeze()` | 删除大小为 1 的维度 |\n",
    "| | `torch.unsqueeze()` | 添加大小为 1 的维度 |\n",
    "| | `torch.permute()` | 重新排列张量的维度 |\n",
    "| | `torch.reshape()`,`torch.view()` | 重塑张量形状 |\n",
    "| **数学操作** | 高级数学函数 (logsumexp, sigmoid, tanh 等) | 应用各种高级数学函数 |\n",
    "| | 归约操作 (argmax, argmin, sum, mean, max 等) | 多维数据的统计运算，如求最大/小值索引、求和、均值等 |\n",
    "| **卷积和池化** | `torch.nn.Conv2d()` | 二维卷积 |\n",
    "| | `torch.nn.MaxPool2d()` | 二维最大池化 |\n",
    "\n",
    "**补充说明：**\n",
    "\n",
    "* 这些操作都支持 GPU 加速。\n",
    "* 高级索引允许更灵活地访问和操作张量。\n",
    "* 维度操作可以改变张量的形状和维度顺序。\n",
    "* 数学操作包括各种数学函数和统计运算。\n",
    "* 卷积和池化是深度学习中常用的操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播计算的规则\n",
    "\n",
    "在 PyTorch 中，广播（Broadcasting）是一种强大的机制，它允许对形状不完全相同的张量进行算术运算。为了更清晰的理解，以下是广播计算的详细规则：\n",
    "\n",
    "**广播的核心思想：**\n",
    "\n",
    "* 使形状不相同的张量能够进行计算，通过在计算时对张量的某些维度进行扩展来实现。\n",
    "* 在实际运行中，并没有真的复制数据，而是在计算过程中“虚拟”的对数据进行了复制。\n",
    "\n",
    "**广播的规则：**\n",
    "\n",
    "当两个张量的形状不兼容时，PyTorch 会尝试应用广播规则。如果可以应用，广播将使这些张量兼容。\n",
    "\n",
    "广播遵循以下规则：\n",
    "\n",
    "| # | 规则描述 | 详细说明 |\n",
    "| - | - | - |\n",
    "| 1 | **维度对齐** | 如果两个张量的维度数不同，则在维度数较小的张量的前面（左侧）填充维度 1，直到两个张量的维度数相同。 |\n",
    "| 2 | **维度匹配** | 对于每个维度，两个张量的大小必须满足以下条件之一：<br/> a. 大小相等。 <br/> b. 其中一个张量的大小为 1。<br/> c. 其中一个张量不存在这个维度。（在PyTorch中，实际效果与大小为1类似，可以理解为此条属于情况b的补充说明） |\n",
    "\n",
    "\n",
    "**广播的运算过程**\n",
    "\n",
    "* 当满足了如上的广播规则后，维度为1的那个维度将会被扩展到和另外一个tensor的对应维度相同的size。\n",
    "* 张量会表现的好像维度为1的那个维度，数据被复制了相同于另外一个tensor的对应的维度的size的次数。\n",
    "\n",
    "**简单总结:**\n",
    "\n",
    "* 从尾部维度开始比较，维度大小相等或其中一个维度为 1 时可以广播。\n",
    "* 若张量维度数量不同，则在数量较小的张量左侧补1直到维度数量相同。\n",
    "* 在可以进行广播的情况下，维度为1的维度进行“虚拟”复制以达到可以运算的状态。\n",
    "\n",
    "**应用场景：**\n",
    "\n",
    "* 张量与标量之间的运算。\n",
    "* 不同形状张量之间的元素级运算。\n",
    "* 卷积运算时的参数广播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结 PyTorch 张量运算的分类\n",
    "\n",
    "| 运算类别         | 具体操作                                                            | 说明                                                            |\n",
    "| ---------------- | ------------------------------------------------------------------- | --------------------------------------------------------------- |\n",
    "| **基本数学运算** | 元素级运算 (+, -, \\*, /, exp, log, abs)                             | 对张量中的每个元素进行操作。                                    |\n",
    "|                  | 矩阵运算 (matmul, mm, @, dot)                                       | 执行矩阵乘法和向量点积。                                        |\n",
    "| **归约运算**     | 统计运算 (sum, mean, max, min, argmax, argmin)                      | 计算张量的统计信息，如总和、均值、最大值、最小值以及它们的索引。|\n",
    "|                  | 逻辑运算 (all, any)                                                 | 对张量中的元素进行逻辑运算。                                    |\n",
    "| **比较运算**     | eq, ne, gt, ge, lt, le                                              | 比较张量中的元素，并返回布尔张量。                              |\n",
    "| **张量操作**     | 形状变换 (reshape, view, t, transpose, unsqueeze, squeeze, permute) | 改变张量的形状和维度。                                          |\n",
    "|                  | 切片和索引 (基本索引和切片，gather, scatter)                        | 访问和修改张量中的元素。                                        |\n",
    "|                  | 连接和分割 (cat, stack, chunk, split)                               | 连接多个张量或将一个张量分割成多个部分。                        |\n",
    "| **线性代数运算** | 矩阵分解 (svd, qr, cholesky)                                        | 执行矩阵的分解操作。                                            |\n",
    "|                  | 求解线性方程组 (solve)                                              | 求解线性方程组。                                                |\n",
    "|                  | 计算逆矩阵 (inv)                                                    | 计算矩阵的逆。                                                  |\n",
    "|                  | 计算特征值和特征向量 (eig, eigh)                                    | 计算矩阵的特征值和特征向量。                                    |\n",
    "| **其他高级操作** | 卷积和池化 (Conv2d, MaxPool2d)                                      | 在图像和信号处理中执行卷积和池化操作。 (位于 `torch.nn` 模块中) |\n",
    "|                  | 激活函数 (sigmoid, relu, tanh)                                      | 在神经网络中应用激活函数。 (位于 `torch.nn.functional` 模块中)  |\n",
    "|                  | 广播 (broadcasting)                                                 | 使形状不兼容的张量可以进行计算。                                |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
