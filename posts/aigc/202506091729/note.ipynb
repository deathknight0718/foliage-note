{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"强化学习专题 - 蒙特卡洛搜索树\"\n",
    "date: 2025-06-06T23:22:00+08:00\n",
    "author: \"Liu Zheng\"\n",
    "tags: [\"笔记\", \"实验\", \"AI\", \"强化学习\"]\n",
    "categories: \"实验笔记\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 蒙特卡洛搜索树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "蒙特卡洛搜索树（Monte Carlo Tree Search, MCTS）是一种基于随机采样的决策过程搜索算法，广泛应用于博弈和强化学习等领域。MCTS 通过模拟和统计的方法，在决策树中选择最优动作，逐步逼近最优策略。\n",
    "\n",
    "在之前的算法实验中，我们都遇到了价值稀疏矩阵，对于 `FrozenLake-v1` 这样的场景，只有成功达到终点的状态才有非零的奖励，而其他状态的奖励都是零。这种稀疏性使得传统的基于 Q 表的学习方法难以有效学习。具体表现在之前的两次实验程序并不是每一次运行都能获得理想的结果，即使我加大了迭代次数，结果也不尽如人意。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
