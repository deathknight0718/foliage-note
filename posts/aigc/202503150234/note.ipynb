{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"强化学习专题 - 首页\"\n",
    "date: 2025-06-04T03:58:00+08:00\n",
    "author: \"Liu Zheng\"\n",
    "tags: [\"笔记\", \"实验\", \"AI\", \"强化学习\"]\n",
    "categories: \"实验笔记\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强化学习专题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练目标\n",
    "\n",
    "我的目标是计划设计一个具备实验性质的战棋类AI，它具备如下需求：\n",
    "\n",
    "1. 三国曹操传式的回合制战棋游戏的强化学习智能体\n",
    "2. 类似于博得之门3的先攻机制，具备明确的回合制竞争\n",
    "3. 人物具备 SP/MP 机制，具备法术系统\n",
    "4. 人物具备进展和远程机制，具备攻击属性\n",
    "5. 人物具备装备机制，具备 BUFF/DEBUFF 系统\n",
    "6. 人物具备反击、防御、命中机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础概念\n",
    "\n",
    "强化学习（Reinforcement Learning, RL）是一种机器学习方法，通过与环境的交互来学习如何采取行动以最大化累积奖励。\n",
    "\n",
    "强化学习的核心思想是智能体（Agent）在环境（Environment）中采取行动（Action），并根据环境的反馈（Reward）来调整其策略（Policy），以期望获得最大的长期回报。\n",
    "\n",
    "强化学习的基本组成部分包括：\n",
    "\n",
    "| 组成部分 | 描述 |\n",
    "| --- | --- |\n",
    "| **智能体（Agent）** | 执行动作并学习的主体。 |\n",
    "| **环境（Environment）** | 智能体与之交互的外部系统。 |\n",
    "| **状态（State）** | 环境在某一时刻的具体情况。 |\n",
    "| **动作（Action）** | 智能体在某一状态下可以采取的行为。 |\n",
    "| **奖励（Reward）** | 智能体采取某一动作后环境反馈的评价值。 |\n",
    "| **策略（Policy）** | 智能体在各个状态下选择动作的规则。 |\n",
    "\n",
    "强化学习的目标是找到一种策略，使得智能体在与环境的长期交互中获得最大的累积奖励。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "[Mastering Reinforcement Learning](https://gibberblot.github.io/rl-notes/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
